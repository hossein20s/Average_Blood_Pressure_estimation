{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of graph.lib.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hossein20s/Average_Blood_Pressure_estimation/blob/master/Copy_of_graph_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOuG3gFm3oQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERSION = '3.9'\n",
        "print('Version ' + VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p62hF1K_DPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "def findImportantFeatures(X, y):\n",
        "\n",
        "  # Build a forest and compute the feature importances\n",
        "  forest = ExtraTreesClassifier(n_estimators=250,\n",
        "                                random_state=0)\n",
        "\n",
        "  forest.fit(X, y)\n",
        "  importances = forest.feature_importances_\n",
        "  std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "               axis=0)\n",
        "  indices = np.argsort(importances)[::-1]\n",
        "\n",
        "  # Print the feature ranking\n",
        "  print(\"Feature ranking:\")\n",
        "\n",
        "  for f in range(X.shape[1]):\n",
        "      print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "  # Plot the feature importances of the forest\n",
        "  plt.figure()\n",
        "  plt.title(\"Feature importances\")\n",
        "  plt.bar(range(X.shape[1]), importances[indices],\n",
        "         color=\"r\", yerr=std[indices], align=\"center\")\n",
        "  plt.xticks(range(X.shape[1]), indices)\n",
        "  plt.xlim([-1, X.shape[1]])\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8721Mgp63nSp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og1kB4n5gkp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(y_actual, y_pred, thresh):\n",
        "    # this function calculates the accuracy with probability threshold at thresh\n",
        "    return (sum((y_pred > thresh) & (y_actual == 1))+sum((y_pred < thresh) & (y_actual == 0))) /len(y_actual)\n",
        "\n",
        "def calc_recall(y_actual, y_pred, thresh):\n",
        "    # calculates the recall\n",
        "    return sum((y_pred > thresh) & (y_actual == 1)) /sum(y_actual)\n",
        "\n",
        "def calc_precision(y_actual, y_pred, thresh):\n",
        "    # calculates the precision\n",
        "    return sum((y_pred > thresh) & (y_actual == 1)) /sum(y_pred > thresh)\n",
        "\n",
        "def calc_specificity(y_actual, y_pred, thresh):\n",
        "    # calculates specificity\n",
        "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
        "\n",
        "def calc_prevalence(y_actual):\n",
        "    # calculates prevalence\n",
        "    return sum((y_actual == 1)) /len(y_actual)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77L56twsgok5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "thresh = 0.5\n",
        "\n",
        "def AUC(y, y_preds):\n",
        "  fpr_train, tpr_train, thresholds_train = roc_curve(y, y_preds)\n",
        "\n",
        "  auc_train = roc_auc_score(y, y_preds)\n",
        "\n",
        "  print('Train AUC:%.3f'%auc_train)\n",
        "\n",
        "  print('Train accuracy:%.3f'%calc_accuracy(y, y_preds, thresh))\n",
        "\n",
        "  print('Train recall:%.3f'%calc_recall(y, y_preds, thresh))\n",
        "\n",
        "  print('Train precision:%.3f'%calc_precision(y, y_preds, thresh))\n",
        "\n",
        "  print('Train specificity:%.3f'%calc_specificity(y, y_preds, thresh))\n",
        "\n",
        "  print('Train prevalence:%.3f'%calc_prevalence(y))\n",
        "\n",
        "  plt.plot(fpr_train, tpr_train,'g-', label = 'Train AUC: %.2f'%auc_train)\n",
        "  plt.plot([0,1],[0,1],'-k')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anrryGs4gvbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "thresh = 0.5\n",
        "\n",
        "def AUC3(y_train_preds,y_train,y_valid_preds,y_valid,y_test_preds,y_test):\n",
        "  fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_preds)\n",
        "  fpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, y_valid_preds)\n",
        "  fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_preds)\n",
        "\n",
        "  auc_train = roc_auc_score(y_train, y_train_preds)\n",
        "  auc_valid = roc_auc_score(y_valid, y_valid_preds)\n",
        "  auc_test = roc_auc_score(y_test, y_test_preds)\n",
        "\n",
        "  print('Train AUC:%.3f'%auc_train)\n",
        "  print('Valid AUC:%.3f'%auc_valid)\n",
        "  print('Test AUC:%.3f'%auc_test)\n",
        "\n",
        "  print('Train accuracy:%.3f'%calc_accuracy(y_train, y_train_preds, thresh))\n",
        "  print('Valid accuracy:%.3f'%calc_accuracy(y_valid, y_valid_preds, thresh))\n",
        "  print('Test accuracy:%.3f'%calc_accuracy(y_test, y_test_preds, thresh))\n",
        "\n",
        "  print('Train recall:%.3f'%calc_recall(y_train, y_train_preds, thresh))\n",
        "  print('Valid recall:%.3f'%calc_recall(y_valid, y_valid_preds, thresh))\n",
        "  print('Test recall:%.3f'%calc_recall(y_test, y_test_preds, thresh))\n",
        "\n",
        "  print('Train precision:%.3f'%calc_precision(y_train, y_train_preds, thresh))\n",
        "  print('Valid precision:%.3f'%calc_precision(y_valid, y_valid_preds, thresh))\n",
        "  print('Test precision:%.3f'%calc_precision(y_test, y_test_preds, thresh))\n",
        "\n",
        "  print('Train specificity:%.3f'%calc_specificity(y_train, y_train_preds, thresh))\n",
        "  print('Valid specificity:%.3f'%calc_specificity(y_valid, y_valid_preds, thresh))\n",
        "  print('Test specificity:%.3f'%calc_specificity(y_test, y_test_preds, thresh))\n",
        "\n",
        "  print('Train prevalence:%.3f'%calc_prevalence(y_train))\n",
        "  print('Valid prevalence:%.3f'%calc_prevalence(y_valid))\n",
        "  print('Test prevalence:%.3f'%calc_prevalence(y_test))\n",
        "\n",
        "  plt.plot(fpr_train, tpr_train,'g-', label = 'Train AUC: %.2f'%auc_train)\n",
        "  plt.plot(fpr_valid, tpr_valid,'b-',label = 'Valid AUC: %.2f'%auc_valid)\n",
        "  plt.plot(fpr_test, tpr_test,'r-',label = 'Test AUC: %.2f'%auc_test)\n",
        "  plt.plot([0,1],[0,1],'-k')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqCr7fHh3N0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics \n",
        "\n",
        "def calculate_errors(y_true, y_pred):\n",
        "  result = metrics.explained_variance_score(y_true, y_pred)\n",
        "  print('explained_variance_score', result) \n",
        "  #result = metrics.max_error(y_true, y_pred)    \n",
        "  #print('max_error', result)\n",
        "  result = metrics.mean_absolute_error(y_true, y_pred)    \n",
        "  print('mean_absolute_error', result)\n",
        "  result = metrics.mean_squared_error(y_true, y_pred)    \n",
        "  print('mean_squared_error', result)\n",
        "  if(sum(n < 0 for n in y_true) == 0):\n",
        "    result = metrics.mean_squared_log_error(y_true, y_pred)    \n",
        "    print('mean_squared_log_error', result)\n",
        "  result = metrics.median_absolute_error(y_true, y_pred)\n",
        "  print('median_absolute_error', result)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZJ56wouhBwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history, x_abs_max, y_abs_max, x_mean_max, y_mean_max):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.xlim([0,x_abs_max])\n",
        "  plt.ylim([0,y_abs_max])\n",
        "  plt.legend()\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.xlim([0,x_mean_max])\n",
        "  plt.ylim([0,y_mean_max])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU9AX4yHODrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(predicted_data, true_data):\n",
        "    fig = plt.figure(facecolor='white')\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data, label='True Data')\n",
        "    plt.plot(predicted_data, label='Prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
        "    fig = plt.figure(facecolor='white')\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(true_data, label='True Data')\n",
        "\t# Pad the list of predictions to shift it in the graph to it's correct start\n",
        "    for i, data in enumerate(predicted_data):\n",
        "        padding = [None for p in range(i * prediction_len)]\n",
        "        plt.plot(padding + data, label='Prediction')\n",
        "        plt.legend()\n",
        "    return plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tziRagqpczkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model_measure(history):\n",
        "  plt.plot(history.history['mean_squared_error'])\n",
        "  plt.plot(history.history['mean_absolute_error'])\n",
        "  plt.plot(history.history['mean_absolute_percentage_error'])\n",
        "  plt.plot(history.history['cosine_proximity'])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ21U1klwYzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_xy_lstm(x1, y1, ymin=None, ymax=None):\n",
        "  plt.plot(x1[:,0,0], 'y')\n",
        "  plt.plot(x1[:,0,1], 'b')\n",
        "  plt.show()\n",
        "  plt.plot(y1[:,0,0],'g')\n",
        "  if ymin is not None and ymax is not None:\n",
        "    plt.ylim(ymin, ymax)\n",
        "  plt.show()\n",
        "\n",
        "def plot_predicts(y_true, y_predicted, ymin=None, ymax=None):\n",
        "  plt.plot(y_true[:,0,0],'g')\n",
        "  plt.plot(y_predicted[:,0,0],'b')\n",
        "  if ymin is not None and ymax is not None:\n",
        "    plt.ylim(ymin, ymax)\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}